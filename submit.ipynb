{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _read32(bytestream):\n",
    "    dt = np.dtype(np.uint32).newbyteorder('>')\n",
    "    return np.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "\n",
    "def extract_images(f):\n",
    "    \"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\n",
    "    Args:\n",
    "    f: A file object that can be passed into a gzip reader.\n",
    "    Returns:\n",
    "    data: A 4D uint8 numpy array [index, y, x, depth].\n",
    "    Raises:\n",
    "    ValueError: If the bytestream does not start with 2051.\n",
    "    \"\"\"\n",
    "    print('Extracting', f.name)\n",
    "    with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "        magic = _read32(bytestream)\n",
    "        \n",
    "        if magic != 2051:\n",
    "            raise ValueError('Invalid magic number %d in MNIST image file: %s' % (magic, f.name))\n",
    "\n",
    "        num_images = _read32(bytestream)\n",
    "        rows = _read32(bytestream)\n",
    "        cols = _read32(bytestream)\n",
    "        buf = bytestream.read(rows * cols * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8)\n",
    "        data = data.reshape(num_images, rows, cols, 1)\n",
    "        return data\n",
    "    \n",
    "def extract_labels(f, one_hot=False, num_classes=10):\n",
    "    \"\"\"Extract the labels into a 1D uint8 numpy array [index].\n",
    "    Args:\n",
    "    f: A file object that can be passed into a gzip reader.\n",
    "    one_hot: Does one hot encoding for the result.\n",
    "    num_classes: Number of classes for the one hot encoding.\n",
    "    Returns:\n",
    "    labels: a 1D uint8 numpy array.\n",
    "    Raises:\n",
    "    ValueError: If the bystream doesn't start with 2049.\n",
    "    \"\"\"\n",
    "    print('Extracting', f.name)\n",
    "    with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "        magic = _read32(bytestream)\n",
    "        \n",
    "        if magic != 2049:\n",
    "            raise ValueError('Invalid magic number %d in MNIST label file: %s' % (magic, f.name))\n",
    "        num_items = _read32(bytestream)\n",
    "        buf = bytestream.read(num_items)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "        if one_hot:\n",
    "            return dense_to_one_hot(labels, num_classes)\n",
    "    return labels\n",
    "    \n",
    "def read_datasets(): \n",
    "    train_images = None\n",
    "    train_labels = None\n",
    "    test_images = None\n",
    "    test_labels =None\n",
    "    \n",
    "    with open(\"./Mnist_data/train-images-idx3-ubyte.gz\", 'rb') as f:\n",
    "        train_images = extract_images(f)\n",
    "        \n",
    "    with open(\"./Mnist_data/train-labels-idx1-ubyte.gz\", 'rb') as f:\n",
    "        train_labels = extract_labels(f)\n",
    "        \n",
    "    with open(\"./Mnist_data/t10k-images-idx3-ubyte.gz\", 'rb') as f:\n",
    "        test_images = extract_images(f)\n",
    "        \n",
    "    with open(\"./Mnist_data/t10k-labels-idx1-ubyte.gz\", 'rb') as f:\n",
    "        test_labels = extract_labels(f)\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_valid_test(train_X, train_y, test_X, test_y):\n",
    "    def softmax(x):\n",
    "        try:\n",
    "            x = x - np.max(x, axis=1)[:, np.newaxis]\n",
    "            return np.exp(x) / np.sum(np.exp(x), axis=1)[:, np.newaxis]\n",
    "        except:\n",
    "            return np.exp(x) / np.sum(np.exp(x), axis=1)[:, np.newaxis]\n",
    "    \n",
    "    def cross_entropy(y, t):\n",
    "        batch_size = y.shape[0]\n",
    "        if y.ndim == 1:\n",
    "            t = t.reshape(1, t.size)\n",
    "            y = y.reshape(1, y.size)\n",
    "\n",
    "        if t.size == y.size:\n",
    "            t = t.argmax(axis=1)\n",
    "        return -np.sum(np.log(y[np.arange(batch_size), t] + 0.001)) / batch_size\n",
    "    \n",
    "    def to_onehot(y):\n",
    "        onehot = np.zeros((y.shape[0], 10))\n",
    "        onehot[np.arange(y.shape[0]), y] = 1\n",
    "        return onehot\n",
    "    \n",
    "    class Relu:\n",
    "        def __init__(self):\n",
    "            self.mask = None\n",
    "\n",
    "        def forward(self, x):\n",
    "            self.mask = (x <= 0)\n",
    "            out = x.copy()\n",
    "            out[self.mask] = 0\n",
    "            return out\n",
    "\n",
    "        def backward(self, dx):\n",
    "            dx[self.mask] = 0\n",
    "            dx = dx\n",
    "            return dx\n",
    "    \n",
    "    class Fully_Layer:\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            self._w = np.random.randn(input_dim, output_dim) * 0.01\n",
    "            self._b = np.zeros((output_dim))\n",
    "            self._x = None\n",
    "            self._lr = 0.01\n",
    "            \n",
    "        def forward(self, x):\n",
    "            self._x = x\n",
    "            return np.dot(self._x, self._w) + self._b\n",
    "        \n",
    "        def backward(self, dx, lr=0.01):\n",
    "            self._lr = lr\n",
    "            self._w -= self._lr * np.dot(self._x.T, dx) \n",
    "            self._b -= self._lr * np.sum(dx, axis=0)\n",
    "            return np.dot(dx, self._w.T)\n",
    "        \n",
    "    class SoftmaxWithLoss:\n",
    "        def __init__(self):\n",
    "            self.loss = None \n",
    "            self.y = None\n",
    "            self.t = None\n",
    "\n",
    "        def forward(self, x, t):\n",
    "            self.t = t\n",
    "            self.y = softmax(x)\n",
    "            self.loss = cross_entropy(self.y, self.t)\n",
    "            return self.loss\n",
    "\n",
    "        def backward(self):\n",
    "            return (self.y - self.t) / self.t.shape[0]\n",
    "                \n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    train_Y = to_onehot(train_y)\n",
    "    \n",
    "    layer_arch = {\n",
    "        \"layer1\" : 512,\n",
    "        \"layer2\": 10,\n",
    "    }\n",
    "    \n",
    "    layer1 = Fully_Layer(train_X.shape[1], layer_arch[\"layer1\"])\n",
    "    relu1 = Relu()\n",
    "    layer2 = Fully_Layer(layer_arch[\"layer1\"], layer_arch[\"layer2\"])\n",
    "    loss = SoftmaxWithLoss()\n",
    "    \n",
    "    batch_size = 32\n",
    "    iter_num = int(np.ceil(train_X.shape[0] / batch_size))\n",
    "    epoch = 50\n",
    "    lr = 0.01\n",
    "    \n",
    "    for ep in range(epoch):\n",
    "        if lr > 0.001:\n",
    "            lr = lr * 0.9\n",
    "        for it in range(iter_num):\n",
    "            output = layer1.forward(train_X[it*batch_size:(it+1)*batch_size])\n",
    "            output = relu1.forward(output)\n",
    "            output = layer2.forward(output)\n",
    "            output = loss.forward(output, train_Y[it*batch_size:(it+1)*batch_size])\n",
    "            dx = loss.backward()\n",
    "            dx = layer2.backward(dx, lr=lr)\n",
    "            dx = relu1.backward(dx)\n",
    "            dx = layer1.backward(dx, lr=lr)\n",
    "    \n",
    "        if ep % 2 == 0:\n",
    "            pred_y = np.argmax(layer2.forward(relu1.forward(layer1.forward(valid_X))), axis=1)\n",
    "            print(\"valid f1 score: {}\".format(f1_score(valid_y, pred_y, average='macro')))\n",
    "            \n",
    "    pred_y = np.argmax(layer2.forward(relu1.forward(layer1.forward(test_X))), axis=1)\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    train_X, train_y, test_X, test_y = read_datasets()\n",
    "    train_X, train_y = shuffle(train_X, train_y, random_state=42)\n",
    "    return train_X / 255., train_y, test_X / 255., test_y\n",
    "\n",
    "def validate_model():\n",
    "    print(\"######## Validate model ########\")\n",
    "    train_X, train_y, test_X, test_y = load_mnist()\n",
    "    train_X = train_X.reshape((train_X.shape[0], -1))\n",
    "    test_X = test_X.reshape((test_X.shape[0], -1))\n",
    "\n",
    "    # validate for small dataset\n",
    "    train_X_mini = train_X[:5000]\n",
    "    train_y_mini = train_y[:5000]\n",
    "    test_X_mini = test_X[:100]\n",
    "    test_y_mini = test_y[:100]\n",
    "        \n",
    "    pred_y = train_valid_test(train_X_mini, train_y_mini, test_X_mini, test_y_mini)    \n",
    "    accuracy = pred_y[pred_y == test_y_mini].shape[0] / float(pred_y.shape[0])\n",
    "    print(\"accuracy: {}\".format(accuracy))\n",
    "\n",
    "def score_model():\n",
    "    print(\"######## Score model ########\")\n",
    "    train_X, train_y, test_X, test_y = load_mnist()\n",
    "    train_X = train_X.reshape((train_X.shape[0], -1))\n",
    "    test_X = test_X.reshape((test_X.shape[0], -1))\n",
    "    \n",
    "    pred_y = train_valid_test(train_X, train_y, test_X, test_y)\n",
    "    accuracy = pred_y[pred_y == test_y].shape[0] / float(pred_y.shape[0])\n",
    "    print(\"accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Validate model ########\n",
      "('Extracting', './Mnist_data/train-images-idx3-ubyte.gz')\n",
      "('Extracting', './Mnist_data/train-labels-idx1-ubyte.gz')\n",
      "('Extracting', './Mnist_data/t10k-images-idx3-ubyte.gz')\n",
      "('Extracting', './Mnist_data/t10k-labels-idx1-ubyte.gz')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsujiyuuki/.pyenv/versions/anaconda-2.4.0/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid f1 score: 0.544438963407\n",
      "valid f1 score: 0.623822766513\n",
      "valid f1 score: 0.688702872997\n",
      "valid f1 score: 0.734933364377\n",
      "valid f1 score: 0.784384650648\n",
      "valid f1 score: 0.799239896894\n",
      "valid f1 score: 0.80870907142\n",
      "valid f1 score: 0.816897523145\n",
      "valid f1 score: 0.821273930132\n",
      "valid f1 score: 0.824851349547\n",
      "valid f1 score: 0.824851349547\n",
      "valid f1 score: 0.826898505273\n",
      "valid f1 score: 0.832742912877\n",
      "valid f1 score: 0.837923968323\n",
      "valid f1 score: 0.839076886194\n",
      "valid f1 score: 0.839017797904\n",
      "valid f1 score: 0.839922634342\n",
      "valid f1 score: 0.842039278736\n",
      "valid f1 score: 0.844352867006\n",
      "valid f1 score: 0.846318489621\n",
      "valid f1 score: 0.848211282347\n",
      "valid f1 score: 0.848211282347\n",
      "valid f1 score: 0.851424139542\n",
      "valid f1 score: 0.853618870078\n",
      "valid f1 score: 0.856654218866\n",
      "accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "validate_model()\n",
    "# score_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
